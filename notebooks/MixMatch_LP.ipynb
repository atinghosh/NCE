{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data2/atin/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import math\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from scipy.sparse.linalg import cg\n",
    "from scipy.sparse import csr_matrix, identity, diags\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import faiss\n",
    "from progressbar import ProgressBar\n",
    "from helper import * \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "model_file_loc = './checkpoint/cifar_fixed_weight_label_unlabel_separate_factor_schedule_all_data_ramp_up_1_lr_point_zero_five.t'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyDataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (linear_embedding): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (linear_class): Linear(in_features=128, out_features=10, bias=False)\n",
       "    (l2norm_for_feature): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "net = ResNet18(pool_len=4, low_dim=128, fixed_weight=True, temperature=.1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    # net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    net = MyDataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load the model\n",
    "state = torch.load(model_file_loc)\n",
    "net.load_state_dict(state['net'])\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "unlabel_index, label_index = generate_subset_of_CIFAR_for_ssl(5000, 25, 1) # Genrate label and unlabel index\n",
    "\n",
    "#create data loaders\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset_no_augment = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform_test)\n",
    "trainset_no_augment = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform_test)\n",
    "\n",
    "combined_dataset_no_aug = torch.utils.data.ConcatDataset([trainset_no_augment, testset_no_augment])\n",
    "combined_dataloader_no_aug = torch.utils.data.DataLoader(combined_dataset_no_aug, batch_size=1024, \n",
    "                                                  shuffle=False, num_workers=20)\n",
    "feature_mat, label_arr = sem_sup_feature(net, combined_dataloader_no_aug)\n",
    "Mat_Label = feature_mat[label_index] #Labelled data matrix\n",
    "labels = label_arr[label_index] #Corresponding labels of Labelled data matrix\n",
    "\n",
    "Mat_Unlabel = feature_mat[unlabel_index] # UnLabelled data matrix\n",
    "rest_label  = label_arr[unlabel_index] # Rest of the lable, won't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_batchsize = 512\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform_train)\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform_train)\n",
    "\n",
    "combined_dataset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "label_sampler = SubsetRandomSampler(label_index)\n",
    "dataloader_label = torch.utils.data.DataLoader(combined_dataset, \n",
    "                                               batch_size=train_batchsize, \n",
    "                                               sampler=label_sampler, \n",
    "                                               num_workers=5)\n",
    "\n",
    "unlabel_sampler = SubsetRandomSampler(unlabel_index)\n",
    "dataloader_unlabel = torch.utils.data.DataLoader(combined_dataset, \n",
    "                                               batch_size=train_batchsize, \n",
    "                                               sampler=unlabel_sampler, \n",
    "                                               num_workers=20)\n",
    "def mixup_aug(input_main, input_noise, beta_param_1=1, beta_param_2=2):\n",
    "    \n",
    "    batch_sz = input_main.size(0)\n",
    "    beta = np.random.beta(beta_param_1, beta_param_2,size=batch_sz)\n",
    "    beta = np.minimum(1. - beta, beta) #dont want beta to be larger than 0.5\n",
    "    beta_array = torch.tensor(beta, dtype=torch.float).to(device)\n",
    "    \n",
    "    inputs_mixup = (1. - beta_array.view(batch_sz,1,1,1))*input_main + \\\n",
    "                            beta_array.view(batch_sz,1,1,1)*input_noise\n",
    "    return inputs_mixup\n",
    "        \n",
    "        \n",
    "        \n",
    "def sem_sup_mixup(net, label_dl, unlabel_dl):\n",
    "    net.eval()\n",
    "    label_dl_iter = iter(label_dl)\n",
    "    \n",
    "    unlabel_feature = []\n",
    "    label_feature = []\n",
    "    target_list = []\n",
    "    for i, (inputs, _) in enumerate(unlabel_dl):\n",
    "        inputs = inputs.to(device)\n",
    "        try:\n",
    "            label_input, target = label_dl_iter.next()\n",
    "        except:\n",
    "            label_dl_iter = iter(label_dl)\n",
    "            label_input, target = label_dl_iter.next()\n",
    "         \n",
    "        label_input, target = label_input.to(device), target.to(device)\n",
    "            \n",
    "        label_batch_sz = label_input.size(0)\n",
    "        unlabel_batch_sz = inputs.size(0)\n",
    "        \n",
    "        label_and_unlabel_inputs = torch.cat([label_input, inputs], dim=0)\n",
    "        index = np.random.choice(unlabel_batch_sz+label_batch_sz,replace=False, size=label_batch_sz)\n",
    "        inputs_shuffled = label_and_unlabel_inputs[index,:,:,:]\n",
    "        inputs_mixup_label = mixup_aug(label_input, inputs_shuffled)\n",
    "    \n",
    "        \n",
    "        idx = torch.randperm(inputs.size(0))\n",
    "        input_a, input_b = inputs, inputs[idx]\n",
    "        \n",
    "        inputs_mixup_unlabel = mixup_aug(input_a, input_b)\n",
    "        inputs_mixup_unlabel = torch.cat([inputs, inputs_mixup_unlabel], dim=0)\n",
    "        with torch.no_grad():\n",
    "            all_pred_unlabel, _ = net(inputs_mixup_unlabel)\n",
    "            all_pred_label, _ = net(inputs_mixup_label)\n",
    "            \n",
    "        unlabel_feature.append(all_pred_unlabel)\n",
    "        label_feature.append(all_pred_label)\n",
    "        target_list.append(target)\n",
    "    \n",
    "    \n",
    "    final_label_feature = torch.cat(label_feature, 0).cpu().numpy()\n",
    "    final_target = torch.cat(target_list, 0).cpu().numpy()\n",
    "    final_unlabel_feature = torch.cat(unlabel_feature, 0).cpu().numpy()\n",
    "    \n",
    "    return final_label_feature, final_target, final_unlabel_feature \n",
    "        \n",
    "    \n",
    "        \n",
    "extra_label_feature, extra_target, extra_unlabel_feature = sem_sup_mixup(net, dataloader_label, dataloader_unlabel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mat_Label = np.concatenate((Mat_Label, extra_label_feature))\n",
    "labels = np.concatenate((labels, extra_target))\n",
    "Mat_Unlabel = np.concatenate((extra_unlabel_feature, Mat_Unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7729 and time for affinity matrix 23 seconds, label propagation time 122 seconds\n"
     ]
    }
   ],
   "source": [
    "# Example of how to do label propagation\n",
    "start_time = time.time()\n",
    "# Two types of disnatce function\n",
    "def trns(x): # taken from this paper https://arxiv.org/pdf/1904.04717.pdf\n",
    "    return 0 if x < 0 else x**5\n",
    "\n",
    "def trns1(x): # this is more traditionally used \n",
    "    distance = (1-x)/2\n",
    "    return math.exp(-(distance**2)/.01)\n",
    "\n",
    "#Stacking features from labelled examples at the begining\n",
    "MatX = np.vstack((Mat_Label, Mat_Unlabel))\n",
    "MatX = MatX / np.linalg.norm(MatX, axis=-1)[:, np.newaxis] # not really required since norm of feature is already 1\n",
    "\n",
    "affinity_matrix = buildGraph(MatX, trns1, 100) # creating sparse affinity matrix\n",
    "affinity_matrix_time = time.time()\n",
    "unlabel_data_labels, unlabel_class_prob = labelPropagation(affinity_matrix, Mat_Label, Mat_Unlabel, labels, alpha=.95, n_iter=300) # Doing LP \n",
    "\n",
    "unlabel_data_labels_rest = unlabel_data_labels[-len(unlabel_index):]\n",
    "accuracy = get_acc(unlabel_data_labels_rest, rest_label) # Measuring accuracy \n",
    "time_taken = time.time() - start_time\n",
    "print(f\"Accuracy is {accuracy:.4f} and time for affinity matrix {affinity_matrix_time - start_time:.0f} seconds, label propagation time {time.time() - affinity_matrix_time:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7554 and time for affinity matrix 14 seconds, label propagation time 243 seconds\n"
     ]
    }
   ],
   "source": [
    "unlabel_data_labels, unlabel_class_prob = labelPropagation(affinity_matrix, Mat_Label, Mat_Unlabel, labels, alpha=.95, n_iter=300) # Doing LP \n",
    "\n",
    "unlabel_data_labels_rest = unlabel_data_labels[-len(unlabel_index):]\n",
    "accuracy = get_acc(unlabel_data_labels_rest, rest_label) # Measuring accuracy \n",
    "time_taken = time.time() - start_time\n",
    "print(f\"Accuracy is {accuracy:.4f} and time for affinity matrix {affinity_matrix_time - start_time:.0f} seconds, label propagation time {time.time() - affinity_matrix_time:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
